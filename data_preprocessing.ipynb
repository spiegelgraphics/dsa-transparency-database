{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import ast\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Categorize Data\n",
    "\n",
    "All columns and values are described here: https://transparency.dsa.ec.europa.eu/page/api-documentation#statement-attributes\n",
    "\n",
    "The data is very heavy. There are many long strings like \"DECISION_PROVISION_PARTIAL_SUSPENSION\". We assign a unique code to each string, store that in a lookup table, and replace the strings with the codes in the data.\n",
    "\n",
    "We do not categorize dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table_path= '../data/processed/category_codes_q4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = pd.DataFrame(columns=['category', 'code'])\n",
    "category_codes.to_csv(lookup_table_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    \"\"\"given a list of lists and other elements, returns a list with all elements\"\"\"\n",
    "    flattened_arr = []\n",
    "    for element in arr:\n",
    "        if isinstance(element, list):\n",
    "            flattened_arr.extend(element)\n",
    "        else:\n",
    "            flattened_arr.append(element)\n",
    "    return flattened_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_value(value):\n",
    "    \"\"\"detects if a string is a list, if yes: for lists with only 1 element, returns the element. For longer lists, returns the original input\"\"\"\n",
    "    if isinstance(value, str) and value.startswith('['):\n",
    "        value = json.loads(value)\n",
    "        if isinstance(value, list) and len(value) == 1:\n",
    "            return value[0]\n",
    "        elif isinstance(value, list):\n",
    "            return json.dumps(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_categorize(column, lookup_table):\n",
    "    \"\"\"given a column of a dataframe, replaces values with codes\"\"\"\n",
    "    column = column.apply(preprocess_value)\n",
    "    # Convert lists to strings\n",
    "    column = column.apply(lambda x: json.dumps(x) if isinstance(x, list) else x)\n",
    "    # Use the global Categorical object to assign codes\n",
    "    mapping_dict = lookup_table.set_index('category').to_dict()['code']\n",
    "    column = column.apply(lambda x: mapping_dict.get(x, None) if pd.notna(x) else None)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_df(df, mapping_table, ignore_cols=[]):\n",
    "    \"\"\"given da dataframe, a lookup table and a list of columns that should not be categorized, replaces strings with categoricals and stores codes and values in a lookup table\"\"\"\n",
    "    \n",
    "    original_df = df.copy()\n",
    "    df = df.drop(columns=ignore_cols)\n",
    "    # find all unique values in the df cells, turn them into a pandas categorical\n",
    "    all_values = pd.Series(df.values.flatten())\n",
    "    all_values = [json.loads(value) if isinstance(value, str) and value.startswith(\"[\") else value for value in all_values]\n",
    "    all_values = flatten(all_values)\n",
    "    categorical = pd.Categorical(all_values)\n",
    "\n",
    "    # Update the lookup table with new categories\n",
    "    new_values = set(categorical.categories) - set(mapping_table[\"category\"].values)\n",
    "    new_entries = pd.DataFrame({\"category\": list(new_values), \"code\": range(len(mapping_table), len(new_values) + len(mapping_table))})\n",
    "    mapping_table = pd.concat([mapping_table, new_entries], ignore_index=True)\n",
    "\n",
    "    # Apply the preprocessing and categorization to all columns\n",
    "    for col in df.columns:\n",
    "        df[col] = preprocess_and_categorize(df[col])\n",
    "\n",
    "    # Add the ignore columns back to the dataframe\n",
    "    df = pd.concat([df, original_df[ignore_cols]], axis=1)\n",
    "\n",
    "    return df, mapping_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean files, categorize, save in sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drops = [\"uuid\",\"content_language\",\"illegal_content_legal_ground\", \"content_type\", \"decision_visibility_other\",\"territorial_scope\", \"decision_monetary_other\", \"account_type\", \"decision_facts\", \"decision_ground_reference_url\", \"illegal_content_explanation\", \"incompatible_content_ground\", \"incompatible_content_explanation\", \"incompatible_content_illegal\", \"content_type_other\", \"category_specification_other\", \"source_identity\", \"platform_uid\"]\n",
    "date_cols = [\"content_date\", \"application_date\", \"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Store all data in an sqlite database\n",
    "\n",
    "For quicker analysis and lighter data, we create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the merged csv files\n",
    "path = \"../data/raw/merged_csv/\"\n",
    "files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "#path for the sqlite database\n",
    "db_path = '../data/processed/2024-q4_data.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(path + file)\n",
    "        print(\"processing file: \", file)\n",
    "        df = df.drop(columns=[col for col in col_drops if col in df.columns]) # Drop columns that are not needed\n",
    "        df = df.astype({col: 'str' for col in df.select_dtypes(include='object').columns}) # Convert remaining object columns to strings       \n",
    "        df, category_codes_q4 = categorize_df(df, category_codes_q4, ignore_cols=date_cols) # categorize the dataframe\n",
    "        df.to_sql('categorized_data', conn, if_exists='append', index=False) # store the dataframe in the database\n",
    "        print(\"stored in db\")\n",
    "        os.remove(path + file) # delete the file\n",
    "        print(\"deleted file\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with file: {file}\")\n",
    "        print(\"Exception: \", e)\n",
    "        pass\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category_codes_q4.to_csv('../data/processed/category_codes_q4_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column with decision-speed in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columns for reaction speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "conn.execute('''\n",
    "            ALTER TABLE categorized_data ADD COLUMN decision_speed_seconds REAL;\n",
    "            ''')\n",
    "\n",
    "conn.execute('''\n",
    "            UPDATE categorized_data\n",
    "            SET decision_speed_seconds = \n",
    "            (JULIANDAY(application_date) - JULIANDAY(content_date))*86400;\n",
    "             ''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Add lookup table in db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the lookup table in the database, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database (or create it)\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "\n",
    "# Connect to the SQLite database (or create it)\n",
    "conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS category_lookup (\n",
    "        category_code TEXT,\n",
    "        category_name TEXT\n",
    "    )\n",
    "''')\n",
    "# Insert data into the category_lookup table\n",
    "for category_code, category_name in global_category_mapping.items():\n",
    "    conn.execute(\"INSERT INTO category_lookup (category_code, category_name) VALUES (?, ?)\", (category_name, category_code))\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
